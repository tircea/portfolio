
# АНАЛІЗ СЕМАНТИЧНОЇ ПОДІБНОСТІ СЛІВ НА ОСНОВІ WORDNET

**Semantic Similarity Analyzer** — консольний застосунок, який дозволяє обчислювати семантичну та символьну подібність між словами англійської мови на основі лінгвістичного ресурсу WordNet. Проєкт створено як демонстрацію базових можливостей обробки лексичної семантики з використанням Python та бібліотеки NLTK.

## Можливості

- Отримання визначень слова з WordNet.
- Виведення гіпонімів і гіперонімів.
- Пошук найнижчого спільного гіпероніма між двома словами.
- Обчислення семантичної подібності:
  - Path Similarity
  - Wu–Palmer Similarity
  - Leacock–Chodorow Similarity
- Обчислення відстані:
  - Левенштейна
  - Дамерау–Левенштейна
- Інтерактивний пошук найближчих за формою слів із файлу.
- Генерація частотного словника із зовнішнього тексту.

## Технології

- Python 3.x
- Бібліотеки:
  - `nltk`
  - `re`
  - `collections.Counter`

## Структура проєкту

- `main.py` — основний файл запуску, містить усі етапи роботи програми.
- `1-1000.txt` — словник слів для символьного порівняння.
- `edgeworth-parents.txt` — текст для побудови частотного словника.
- `sorted_words.txt` — згенерований словник частот.

## Запуск

1. Встановіть бібліотеку NLTK, якщо ще не встановлена:

   ```bash
   pip install nltk
   ```

2. Запустіть скрипт:

   ```bash
   python main.py
   ```

3. Програма попросить ввести слово англійською — введіть будь-яке слово, і система знайде найближчі за формою слова з `1-1000.txt`.

> Для коректної роботи необхідно попередньо завантажити ресурси WordNet:

```python
import nltk
nltk.download('wordnet')
```
